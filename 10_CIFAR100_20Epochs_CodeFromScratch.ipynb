{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_CIFAR100_20Epochs_CodeFromScratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHsPHrDk-Ee0",
        "outputId": "acbbc1c9-62b2-48c9-f97d-df0488395a35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V35ySJYcCFoc",
        "outputId": "00e31be4-4840-48ab-814c-f3e437fd5c6d"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# args = {'output_dir': 'permuted_mnist_results',\n",
        "#         'output_name': 'permuted_mnist_sorted',\n",
        "#         'input_dir':'permuted_mnist_results',\n",
        "#         'epochs': 20,\n",
        "#         'input_fname_args':\n",
        "#         {\n",
        "#             'dataset': 'permuted_mnist',\n",
        "#             'no_droput': False,\n",
        "#             'sorting_file': 'none',\n",
        "#             'remove_n': 0,\n",
        "#             'keep_lowest_n': 0\n",
        "\n",
        "#         }\n",
        "\n",
        "#         }\n",
        "\n",
        "\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "%cd drive\n",
        "%cd MyDrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "drive  sample_data\n",
            "/content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAVhVb0i-UKU",
        "outputId": "6bd93b71-4f5e-44a4-a2ec-15eded1541b2"
      },
      "source": [
        "!git clone https://github.com/mtoneva/example_forgetting.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'example_forgetting'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Total 194 (delta 0), reused 0 (delta 0), pack-reused 194\u001b[K\n",
            "Receiving objects: 100% (194/194), 566.18 KiB | 6.82 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyCLqv4J-tXf",
        "outputId": "a9afb7b1-aa90-43c3-aab6-bf32587dd87b"
      },
      "source": [
        "%cd example_forgetting/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/example_forgetting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2swMilJ2-wXq",
        "outputId": "79590528-b60b-4743-b23d-ffc93c007d2f"
      },
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting torch==0.4.1.post2\n",
            "  Downloading torch-0.4.1.post2-cp37-cp37m-manylinux1_x86_64.whl (519.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 519.5 MB 22 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.1.8\n",
            "  Downloading torchvision-0.1.8-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from torchvision==0.1.8->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.1.8->-r requirements.txt (line 3)) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 0.4.1.post2 which is incompatible.\n",
            "fastai 1.0.61 requires torch>=1.0.0, but you have torch 0.4.1.post2 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-0.4.1.post2 torchvision-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGT9kP5V-0g8"
      },
      "source": [
        "import pdb\n",
        "import argparse\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from Cutout.util.misc import CSVLogger\n",
        "from Cutout.util.cutout import Cutout\n",
        "\n",
        "from Cutout.model.resnet import ResNet18\n",
        "from Cutout.model.wide_resnet import WideResNet\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNeUw6A3wVI6"
      },
      "source": [
        "\n",
        "# Format time for printing purposes\n",
        "def get_hms(seconds):\n",
        "    m, s = divmod(seconds, 60)\n",
        "    h, m = divmod(m, 60)\n",
        "\n",
        "    return h, m, s\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtmqwzib-TFf"
      },
      "source": [
        "\n",
        "# Introduce Gaussian noise to noise_percentage of image pixels\n",
        "def noisy(image, noise_percentage, noise_std):\n",
        "    row, col, ch = image.shape\n",
        "    num_corrupt = int(np.floor(noise_percentage * row * col / 100))\n",
        "\n",
        "    # Randomly choose pixels to add noise to\n",
        "    xy_coords = np.random.choice(row * col, num_corrupt, replace=False)\n",
        "    chan_coords = np.random.choice(ch, num_corrupt, replace=True)\n",
        "    xy_coords = np.unravel_index(xy_coords, (row, col))\n",
        "\n",
        "    out = np.copy(image)\n",
        "\n",
        "    mean = 120\n",
        "\n",
        "    # Add randomly generated Gaussian noise to pixels\n",
        "    for coord in range(num_corrupt):\n",
        "        noise = np.random.normal(mean, noise_std, 1)\n",
        "        out[xy_coords[0][coord], xy_coords[1][coord],\n",
        "            chan_coords[coord]] += noise\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ua-ldCG-VLC"
      },
      "source": [
        "#args\n",
        "# Train model for one epoch\n",
        "#\n",
        "# example_stats: dictionary containing statistics accumulated over every presentation of example\n",
        "#\n",
        "def train(args, model, device, trainset, model_optimizer, epoch,\n",
        "          example_stats):\n",
        "    train_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Get permutation to shuffle trainset\n",
        "    trainset_permutation_inds = npr.permutation(\n",
        "        np.arange(len(trainset.train_labels)))\n",
        "\n",
        "    print('\\n=> Training Epoch #%d' % (epoch))\n",
        "\n",
        "    batch_size = args['batch_size']\n",
        "    for batch_idx, batch_start_ind in enumerate(\n",
        "            range(0, len(trainset.train_labels), batch_size)):\n",
        "\n",
        "        # Get trainset indices for batch\n",
        "        batch_inds = trainset_permutation_inds[batch_start_ind:\n",
        "                                               batch_start_ind + batch_size]\n",
        "\n",
        "        # Get batch inputs and targets, transform them appropriately\n",
        "        transformed_trainset = []\n",
        "        for ind in batch_inds:\n",
        "            transformed_trainset.append(trainset.__getitem__(ind)[0])\n",
        "        inputs = torch.stack(transformed_trainset)\n",
        "        targets = torch.LongTensor(\n",
        "            np.array(trainset.train_labels)[batch_inds].tolist())\n",
        "\n",
        "        # Map to available device\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward propagation, compute loss, get predictions\n",
        "        model_optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update statistics and loss\n",
        "        acc = predicted == targets\n",
        "        for j, index in enumerate(batch_inds):\n",
        "\n",
        "            # Get index in original dataset (not sorted by forgetting)\n",
        "            index_in_original_dataset = train_indx[index]\n",
        "\n",
        "            # Compute missclassification margin\n",
        "            output_correct_class = outputs.data[j, targets[j].item()]\n",
        "            sorted_output, _ = torch.sort(outputs.data[j, :])\n",
        "            if acc[j]:\n",
        "                # Example classified correctly, highest incorrect class is 2nd largest output\n",
        "                output_highest_incorrect_class = sorted_output[-2]\n",
        "            else:\n",
        "                # Example misclassified, highest incorrect class is max output\n",
        "                output_highest_incorrect_class = sorted_output[-1]\n",
        "            margin = output_correct_class.item(\n",
        "            ) - output_highest_incorrect_class.item()\n",
        "\n",
        "            # Add the statistics of the current training example to dictionary\n",
        "            index_stats = example_stats.get(index_in_original_dataset,\n",
        "                                            [[], [], []])\n",
        "            index_stats[0].append(loss[j].item())\n",
        "            index_stats[1].append(acc[j].sum().item())\n",
        "            index_stats[2].append(margin)\n",
        "            example_stats[index_in_original_dataset] = index_stats\n",
        "\n",
        "        # Update loss, backward propagate, update optimizer\n",
        "        loss = loss.mean()\n",
        "        train_loss += loss.item()\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "        loss.backward()\n",
        "        model_optimizer.step()\n",
        "\n",
        "        sys.stdout.write('\\r')\n",
        "        sys.stdout.write(\n",
        "            '| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%' %\n",
        "            (epoch, args['epochs'], batch_idx + 1,\n",
        "             (len(trainset) // batch_size) + 1, loss.item(),\n",
        "             100. * correct.item() / total))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # Add training accuracy to dict\n",
        "        index_stats = example_stats.get('train', [[], []])\n",
        "        index_stats[1].append(100. * correct.item() / float(total))\n",
        "        example_stats['train'] = index_stats\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxJtG9uJ-XrU"
      },
      "source": [
        "#args\n",
        "# Evaluate model predictions on heldout test data\n",
        "#\n",
        "# example_stats: dictionary containing statistics accumulated over every presentation of example\n",
        "#\n",
        "def test(epoch, model, device, example_stats):\n",
        "    global best_acc\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    test_batch_size = 32\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_idx, batch_start_ind in enumerate(\n",
        "            range(0, len(test_dataset.test_labels), test_batch_size)):\n",
        "\n",
        "        # Get batch inputs and targets\n",
        "        transformed_testset = []\n",
        "        for ind in range(\n",
        "                batch_start_ind,\n",
        "                min(\n",
        "                    len(test_dataset.test_labels),\n",
        "                    batch_start_ind + test_batch_size)):\n",
        "            transformed_testset.append(test_dataset.__getitem__(ind)[0])\n",
        "        inputs = torch.stack(transformed_testset)\n",
        "        targets = torch.LongTensor(\n",
        "            np.array(\n",
        "                test_dataset.test_labels)[batch_start_ind:batch_start_ind +\n",
        "                                          test_batch_size].tolist())\n",
        "\n",
        "        # Map to available device\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward propagation, compute loss, get predictions\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss = loss.mean()\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets.data).cpu().sum()\n",
        "\n",
        "    # Add test accuracy to dict\n",
        "    acc = 100. * correct.item() / total\n",
        "    index_stats = example_stats.get('test', [[], []])\n",
        "    index_stats[1].append(100. * correct.item() / float(total))\n",
        "    example_stats['test'] = index_stats\n",
        "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %\n",
        "          (epoch, loss.item(), acc))\n",
        "\n",
        "    # Save checkpoint when best model\n",
        "    if acc > best_acc:\n",
        "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' % (acc))\n",
        "        state = {\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        save_point = os.path.join(args['output_dir'], 'checkpoint', args['dataset'])\n",
        "        os.makedirs(save_point, exist_ok=True)\n",
        "        torch.save(state, os.path.join(save_point, save_fname + '.t7'))\n",
        "        best_acc = acc\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfx2ajf2-aCp"
      },
      "source": [
        "\n",
        "model_options = ['resnet18', 'wideresnet']\n",
        "dataset_options = ['cifar10', 'cifar100']\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR6z1G7q-cBc"
      },
      "source": [
        "args = {'dataset': 'cifar100',\n",
        "        'model':'resnet18',\n",
        "        'batch_size': 128,\n",
        "        'epochs':20,\n",
        "        'learning_rate':0.01,\n",
        "        'data_augmentation':False,\n",
        "        'cutout':False,\n",
        "        'n_holes':1,\n",
        "        'length':16,\n",
        "        'no_cuda':False,\n",
        "        'seed':2,\n",
        "        'sorting_file':\"none\",\n",
        "        'remove_n':0,\n",
        "        'keep_lowest_n':0,\n",
        "        'no_dropout':False,\n",
        "        'remove_subsample':0,\n",
        "        'noise_percent_labels':0,\n",
        "        'noise_percent_pixels':0,\n",
        "        'noise_std_pixels':0,\n",
        "        'optimizer':'sgd',\n",
        "        'input_dir':'cifar100_results/',\n",
        "        'output_dir':'cifar100_results/'\n",
        "\n",
        "        }\n",
        "\n",
        "# Enter all arguments that you want to be in the filename of the saved output\n",
        "ordered_args = [\n",
        "    'dataset', 'data_augmentation', 'cutout', 'seed', 'sorting_file',\n",
        "    'remove_n', 'keep_lowest_n', 'remove_subsample', 'noise_percent_labels',\n",
        "    'noise_percent_pixels', 'noise_std_pixels'\n",
        "]\n",
        "# # Parse arguments and setup name of output file with forgetting stats\n",
        "# args = parser.parse_args()\n",
        "args_dict = args\n",
        "# print(args_dict)\n",
        "save_fname = '__'.join(\n",
        "    '{}_{}'.format(arg, args_dict[arg]) for arg in ordered_args)\n",
        "\n",
        "# Set appropriate devices\n",
        "args['cuda'] = not args['no_cuda'] and torch.cuda.is_available()\n",
        "use_cuda = args['cuda']\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "cudnn.benchmark = True  # Should make training go faster for large models\n",
        "\n",
        "# Set random seed for initialization\n",
        "torch.manual_seed(args['seed'])\n",
        "if args['cuda']:\n",
        "    torch.cuda.manual_seed(args['seed'])\n",
        "npr.seed(args['seed'])\n",
        "\n",
        "# Image Preprocessing\n",
        "normalize = transforms.Normalize(\n",
        "    mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "    std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "# Setup train transforms\n",
        "train_transform = transforms.Compose([])\n",
        "if args['data_augmentation']:\n",
        "    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "if args['cutout']:\n",
        "    train_transform.transforms.append(\n",
        "        Cutout(n_holes=args['n_holes'], length=args['length']))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g69Tvj0f-e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f14ab2-46ac-4424-9756-99c2709074c7"
      },
      "source": [
        "\n",
        "# Setup test transforms\n",
        "test_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "os.makedirs(args['output_dir'], exist_ok=True)\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "!tar -zxvf cifar-10-python.tar.gz\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "!tar -zxvf cifar-100-python.tar.gz\n",
        "\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "if args['dataset'] == 'cifar10':\n",
        "  num_classes=10\n",
        "  train_dataset = CIFAR10('./', download=True,\n",
        "  transform=transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  ]), train=True)\n",
        "\n",
        "\n",
        "  test_dataset = CIFAR10('./', download=True,\n",
        "  transform=transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  ]), train=False)\n",
        "\n",
        "elif args['dataset'] == 'cifar100':\n",
        "  num_classes=100\n",
        "  train_dataset = CIFAR100('./', download=True,\n",
        "  transform=transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  ]), train=True)\n",
        "\n",
        "\n",
        "  test_dataset = CIFAR100('./', download=True,\n",
        "  transform=transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  ]), train=False)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-10 07:37:51--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  29.0MB/s    in 6.8s    \n",
            "\n",
            "2021-09-10 07:37:58 (24.0 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n",
            "--2021-09-10 07:38:02--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  19.9MB/s    in 7.6s    \n",
            "\n",
            "2021-09-10 07:38:10 (21.1 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "cifar-100-python/\n",
            "cifar-100-python/file.txt~\n",
            "cifar-100-python/train\n",
            "cifar-100-python/test\n",
            "cifar-100-python/meta\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc0zbOtf-hG1"
      },
      "source": [
        "\n",
        "# Get indices of examples that should be used for training\n",
        "if args['sorting_file'] == 'none':\n",
        "    train_indx = np.array(range(len(train_dataset.train_labels)))\n",
        "else:\n",
        "    try:\n",
        "        with open(\n",
        "                os.path.join(args['input_dir'], args['sorting_file']) + '.pkl',\n",
        "                'rb') as fin:\n",
        "            ordered_indx = pickle.load(fin)['indices']\n",
        "    except IOError:\n",
        "        with open(os.path.join(args['input_dir'], args['sorting_file']),\n",
        "                  'rb') as fin:\n",
        "            ordered_indx = pickle.load(fin)['indices']\n",
        "\n",
        "    # Get the indices to remove from training\n",
        "    elements_to_remove = np.array(\n",
        "        ordered_indx)[args['keep_lowest_n']:args['keep_lowest_n'] + args['remove_n']]\n",
        "\n",
        "    # Remove the corresponding elements\n",
        "    train_indx = np.setdiff1d(\n",
        "        range(len(train_dataset.train_labels)), elements_to_remove)\n",
        "\n",
        "if args['keep_lowest_n'] < 0:\n",
        "    # Remove remove_n number of examples from the train set at random\n",
        "    train_indx = npr.permutation(np.arange(len(\n",
        "        train_dataset.train_labels)))[:len(train_dataset.train_labels) -\n",
        "                                      args['remove_n']]\n",
        "\n",
        "elif args['remove_subsample']:\n",
        "    # Remove remove_sample number of examples at random from the first keep_lowest_n examples\n",
        "    # Useful when the first keep_lowest_n examples have equal forgetting counts\n",
        "    lowest_n = np.array(ordered_indx)[0:args['keep_lowest_n']]\n",
        "    train_indx = lowest_n[npr.permutation(np.arange(\n",
        "        args['keep_lowest_n']))[:args['keep_lowest_n'] - args['remove_subsample']]]\n",
        "    train_indx = np.hstack((train_indx,\n",
        "                            np.array(ordered_indx)[args['keep_lowest_n']:]))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Htn5aDU-mh3"
      },
      "source": [
        "#args\n",
        "# Reassign train data and labels\n",
        "train_dataset.train_data = train_dataset.train_data[train_indx, :, :, :]\n",
        "train_dataset.train_labels = np.array(\n",
        "    train_dataset.train_labels)[train_indx].tolist()\n",
        "\n",
        "# Introduce noise to images if specified\n",
        "if args['noise_percent_pixels']:\n",
        "    for ind in range(len(train_indx)):\n",
        "        image = train_dataset.train_data[ind, :, :, :]\n",
        "        noisy_image = noisy(image, args['noise_percent_pixels'], args['noise_std_pixels'])\n",
        "        train_dataset.train_data[ind, :, :, :] = noisy_image\n",
        "\n",
        "# Introduce noise to labels if specified\n",
        "if args['noise_percent_labels']:\n",
        "    fname = os.path.join(args['output_dir'], save_fname)\n",
        "\n",
        "    with open(fname + \"_changed_labels.txt\", \"w\") as f:\n",
        "\n",
        "        # Compute number of labels to change\n",
        "        nlabels = len(train_dataset.train_labels)\n",
        "        nlabels_to_change = int(args['noise_percent_labels'] * nlabels / 100)\n",
        "        ntrain_labels = len(np.unique(train_dataset.train_labels))\n",
        "        print('flipping ' + str(nlabels_to_change) + ' labels')\n",
        "\n",
        "        # Randomly choose which labels to change, get indices\n",
        "        labels_inds_to_change = npr.choice(\n",
        "            np.arange(nlabels), nlabels_to_change, replace=False)\n",
        "\n",
        "        # Flip each of the randomly chosen labels\n",
        "        for l, label_ind_to_change in enumerate(labels_inds_to_change):\n",
        "\n",
        "            # Possible choices for new label\n",
        "            label_choices = np.arange(ntrain_labels)\n",
        "\n",
        "            # Get true label to remove it from the choices\n",
        "            true_label = train_dataset.train_labels[label_ind_to_change]\n",
        "\n",
        "            # Remove true label from choices\n",
        "            label_choices = np.delete(\n",
        "                label_choices,\n",
        "                true_label)  # the label is the same as the index of the label\n",
        "\n",
        "            # Get new label and relabel the example with it\n",
        "            noisy_label = npr.choice(label_choices, 1)\n",
        "            train_dataset.train_labels[label_ind_to_change] = noisy_label[0]\n",
        "\n",
        "            # Write the example index from the original example order, the old, and the new label\n",
        "            f.write(\n",
        "                str(train_indx[label_ind_to_change]) + ' ' + str(true_label) +\n",
        "                ' ' + str(noisy_label[0]) + '\\n')\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gErh1kyb-o3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa01764b-b9be-4762-b317-5696da788da5"
      },
      "source": [
        "print('Training on ' + str(len(train_dataset.train_labels)) + ' examples')\n",
        "\n",
        "# Setup model\n",
        "if args['model'] == 'resnet18':\n",
        "    model = ResNet18(num_classes=num_classes)\n",
        "elif args['model'] == 'wideresnet':\n",
        "    if args['dataset'] == 'svhn':\n",
        "        model = WideResNet(\n",
        "            depth=16, num_classes=num_classes, widen_factor=8, dropRate=0.4)\n",
        "    else:\n",
        "        model = WideResNet(\n",
        "            depth=28, num_classes=num_classes, widen_factor=10, dropRate=0.3)\n",
        "else:\n",
        "    print(\n",
        "        'Specified model not recognized. Options are: resnet18 and wideresnet')\n",
        "\n",
        "# Setup loss\n",
        "model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "criterion.__init__(reduce=False)\n",
        "\n",
        "# Setup optimizer\n",
        "if args['optimizer'] == 'adam':\n",
        "    model_optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "elif args['optimizer'] == 'sgd':\n",
        "    model_optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=args['learning_rate'],\n",
        "        momentum=0.9,\n",
        "        nesterov=True,\n",
        "        weight_decay=5e-4)\n",
        "    scheduler = MultiStepLR(\n",
        "        model_optimizer, milestones=[60, 120, 160], gamma=0.2)\n",
        "else:\n",
        "    print('Specified optimizer not recognized. Options are: adam and sgd')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 50000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la1AkhEb-roU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6570f2-3a40-4c60-9e59-9354253a1d4f"
      },
      "source": [
        "\n",
        "# Initialize dictionary to save statistics for every example presentation\n",
        "example_stats = {}\n",
        "\n",
        "best_acc = 0\n",
        "elapsed_time = 0\n",
        "for epoch in range(20):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train(args, model, device, train_dataset, model_optimizer, epoch, example_stats)\n",
        "    test(epoch, model, device, example_stats)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    elapsed_time += epoch_time\n",
        "    print('| Elapsed time : %d:%02d:%02d' % (get_hms(elapsed_time)))\n",
        "\n",
        "    # Update optimizer step\n",
        "    if args['optimizer'] == 'sgd':\n",
        "        scheduler.step(epoch)\n",
        "\n",
        "    # Save the stats dictionary\n",
        "    fname = os.path.join(args['output_dir'], save_fname)\n",
        "    with open(fname + \"__stats_dict.pkl\", \"wb\") as f:\n",
        "        pickle.dump(example_stats, f)\n",
        "\n",
        "    # Log the best train and test accuracy so far\n",
        "    with open(fname + \"__best_acc.txt\", \"w\") as f:\n",
        "        f.write('train test \\n')\n",
        "        f.write(str(max(example_stats['train'][1])))\n",
        "        f.write(' ')\n",
        "        f.write(str(max(example_stats['test'][1])))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=> Training Epoch #0\n",
            "| Epoch [  0/ 20] Iter[391/391]\t\tLoss: 3.2934 Acc@1: 15.098%\n",
            "| Validation Epoch #0\t\t\tLoss: 3.4130 Acc@1: 18.29%\n",
            "| Saving Best model...\t\t\tTop1 = 18.29%\n",
            "| Elapsed time : 0:01:57\n",
            "\n",
            "=> Training Epoch #1\n",
            "| Epoch [  1/ 20] Iter[391/391]\t\tLoss: 2.3406 Acc@1: 31.256%\n",
            "| Validation Epoch #1\t\t\tLoss: 2.6277 Acc@1: 17.09%\n",
            "| Elapsed time : 0:03:50\n",
            "\n",
            "=> Training Epoch #2\n",
            "| Epoch [  2/ 20] Iter[391/391]\t\tLoss: 1.8912 Acc@1: 42.278%\n",
            "| Validation Epoch #2\t\t\tLoss: 2.8057 Acc@1: 33.67%\n",
            "| Saving Best model...\t\t\tTop1 = 33.67%\n",
            "| Elapsed time : 0:05:43\n",
            "\n",
            "=> Training Epoch #3\n",
            "| Epoch [  3/ 20] Iter[391/391]\t\tLoss: 1.8820 Acc@1: 50.368%\n",
            "| Validation Epoch #3\t\t\tLoss: 1.6283 Acc@1: 46.86%\n",
            "| Saving Best model...\t\t\tTop1 = 46.86%\n",
            "| Elapsed time : 0:07:36\n",
            "\n",
            "=> Training Epoch #4\n",
            "| Epoch [  4/ 20] Iter[391/391]\t\tLoss: 1.3607 Acc@1: 57.482%\n",
            "| Validation Epoch #4\t\t\tLoss: 2.0550 Acc@1: 42.95%\n",
            "| Elapsed time : 0:09:29\n",
            "\n",
            "=> Training Epoch #5\n",
            "| Epoch [  5/ 20] Iter[391/391]\t\tLoss: 1.2283 Acc@1: 63.826%\n",
            "| Validation Epoch #5\t\t\tLoss: 1.9248 Acc@1: 45.99%\n",
            "| Elapsed time : 0:11:22\n",
            "\n",
            "=> Training Epoch #6\n",
            "| Epoch [  6/ 20] Iter[391/391]\t\tLoss: 1.1494 Acc@1: 69.770%\n",
            "| Validation Epoch #6\t\t\tLoss: 1.6764 Acc@1: 47.40%\n",
            "| Saving Best model...\t\t\tTop1 = 47.40%\n",
            "| Elapsed time : 0:13:15\n",
            "\n",
            "=> Training Epoch #7\n",
            "| Epoch [  7/ 20] Iter[391/391]\t\tLoss: 1.0011 Acc@1: 76.210%\n",
            "| Validation Epoch #7\t\t\tLoss: 1.9569 Acc@1: 46.09%\n",
            "| Elapsed time : 0:15:07\n",
            "\n",
            "=> Training Epoch #8\n",
            "| Epoch [  8/ 20] Iter[391/391]\t\tLoss: 0.6647 Acc@1: 82.374%\n",
            "| Validation Epoch #8\t\t\tLoss: 1.2578 Acc@1: 52.10%\n",
            "| Saving Best model...\t\t\tTop1 = 52.10%\n",
            "| Elapsed time : 0:17:00\n",
            "\n",
            "=> Training Epoch #9\n",
            "| Epoch [  9/ 20] Iter[391/391]\t\tLoss: 0.6968 Acc@1: 87.672%\n",
            "| Validation Epoch #9\t\t\tLoss: 1.8813 Acc@1: 49.02%\n",
            "| Elapsed time : 0:18:53\n",
            "\n",
            "=> Training Epoch #10\n",
            "| Epoch [ 10/ 20] Iter[391/391]\t\tLoss: 0.3581 Acc@1: 92.620%\n",
            "| Validation Epoch #10\t\t\tLoss: 1.9231 Acc@1: 48.84%\n",
            "| Elapsed time : 0:20:46\n",
            "\n",
            "=> Training Epoch #11\n",
            "| Epoch [ 11/ 20] Iter[391/391]\t\tLoss: 0.1760 Acc@1: 96.084%\n",
            "| Validation Epoch #11\t\t\tLoss: 1.4335 Acc@1: 50.66%\n",
            "| Elapsed time : 0:22:39\n",
            "\n",
            "=> Training Epoch #12\n",
            "| Epoch [ 12/ 20] Iter[391/391]\t\tLoss: 0.1380 Acc@1: 98.672%\n",
            "| Validation Epoch #12\t\t\tLoss: 1.2482 Acc@1: 53.89%\n",
            "| Saving Best model...\t\t\tTop1 = 53.89%\n",
            "| Elapsed time : 0:24:32\n",
            "\n",
            "=> Training Epoch #13\n",
            "| Epoch [ 13/ 20] Iter[391/391]\t\tLoss: 0.0200 Acc@1: 99.718%\n",
            "| Validation Epoch #13\t\t\tLoss: 1.3130 Acc@1: 56.16%\n",
            "| Saving Best model...\t\t\tTop1 = 56.16%\n",
            "| Elapsed time : 0:26:25\n",
            "\n",
            "=> Training Epoch #14\n",
            "| Epoch [ 14/ 20] Iter[391/391]\t\tLoss: 0.0151 Acc@1: 99.936%\n",
            "| Validation Epoch #14\t\t\tLoss: 1.2618 Acc@1: 57.47%\n",
            "| Saving Best model...\t\t\tTop1 = 57.47%\n",
            "| Elapsed time : 0:28:17\n",
            "\n",
            "=> Training Epoch #15\n",
            "| Epoch [ 15/ 20] Iter[391/391]\t\tLoss: 0.0121 Acc@1: 99.952%\n",
            "| Validation Epoch #15\t\t\tLoss: 1.1166 Acc@1: 57.76%\n",
            "| Saving Best model...\t\t\tTop1 = 57.76%\n",
            "| Elapsed time : 0:30:11\n",
            "\n",
            "=> Training Epoch #16\n",
            "| Epoch [ 16/ 20] Iter[391/391]\t\tLoss: 0.0103 Acc@1: 99.964%\n",
            "| Validation Epoch #16\t\t\tLoss: 1.2069 Acc@1: 57.60%\n",
            "| Elapsed time : 0:32:04\n",
            "\n",
            "=> Training Epoch #17\n",
            "| Epoch [ 17/ 20] Iter[391/391]\t\tLoss: 0.0084 Acc@1: 99.964%\n",
            "| Validation Epoch #17\t\t\tLoss: 1.1452 Acc@1: 57.83%\n",
            "| Saving Best model...\t\t\tTop1 = 57.83%\n",
            "| Elapsed time : 0:33:57\n",
            "\n",
            "=> Training Epoch #18\n",
            "| Epoch [ 18/ 20] Iter[391/391]\t\tLoss: 0.0068 Acc@1: 99.972%\n",
            "| Validation Epoch #18\t\t\tLoss: 1.0765 Acc@1: 57.61%\n",
            "| Elapsed time : 0:35:51\n",
            "\n",
            "=> Training Epoch #19\n",
            "| Epoch [ 19/ 20] Iter[391/391]\t\tLoss: 0.0065 Acc@1: 99.972%\n",
            "| Validation Epoch #19\t\t\tLoss: 1.2211 Acc@1: 58.02%\n",
            "| Saving Best model...\t\t\tTop1 = 58.02%\n",
            "| Elapsed time : 0:37:44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdfq3_GTLYIj"
      },
      "source": [
        "# python order_examples_by_forgetting.py \n",
        "#     --output_dir [cifar10/cifar100]_results \n",
        "#     --output_name [cifar10/cifar100]_sorted \n",
        "#     --input_dir [cifar10/cifar100]_results \n",
        "#     --input_fname_args \n",
        "#             dataset [cifar10/cifar100]\n",
        "#             data_augmentation True \n",
        "#             cutout False \n",
        "#             sorting_file none \n",
        "#             remove_n 0 \n",
        "#             keep_lowest_n 0 \n",
        "#             remove_subsample 0 \n",
        "#             noise_percent_labels 0 \n",
        "#             noise_percent_pixels 0 \n",
        "#             noise_std_pixels 0\n",
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Es9Z_DsN3iH"
      },
      "source": [
        "#args\n",
        "\n",
        "def compute_forgetting_statistics(diag_stats, npresentations):\n",
        "\n",
        "    presentations_needed_to_learn = {}\n",
        "    unlearned_per_presentation = {}\n",
        "    margins_per_presentation = {}\n",
        "    first_learned = {}\n",
        "\n",
        "    for example_id, example_stats in diag_stats.items():\n",
        "\n",
        "        # Skip 'train' and 'test' keys of diag_stats\n",
        "        if not isinstance(example_id, str):\n",
        "\n",
        "            # Forgetting event is a transition in accuracy from 1 to 0\n",
        "            presentation_acc = np.array(example_stats[1][:npresentations])\n",
        "            transitions = presentation_acc[1:] - presentation_acc[:-1]\n",
        "\n",
        "            # Find all presentations when forgetting occurs\n",
        "            if len(np.where(transitions == -1)[0]) > 0:\n",
        "                unlearned_per_presentation[example_id] = np.where(\n",
        "                    transitions == -1)[0] + 2\n",
        "            else:\n",
        "                unlearned_per_presentation[example_id] = []\n",
        "\n",
        "            # Find number of presentations needed to learn example, \n",
        "            # e.g. last presentation when acc is 0\n",
        "            if len(np.where(presentation_acc == 0)[0]) > 0:\n",
        "                presentations_needed_to_learn[example_id] = np.where(\n",
        "                    presentation_acc == 0)[0][-1] + 1\n",
        "            else:\n",
        "                presentations_needed_to_learn[example_id] = 0\n",
        "\n",
        "            # Find the misclassication margin for each presentation of the example\n",
        "            margins_per_presentation = np.array(\n",
        "                example_stats[2][:npresentations])\n",
        "\n",
        "            # Find the presentation at which the example was first learned, \n",
        "            # e.g. first presentation when acc is 1\n",
        "            if len(np.where(presentation_acc == 1)[0]) > 0:\n",
        "                first_learned[example_id] = np.where(\n",
        "                    presentation_acc == 1)[0][0]\n",
        "            else:\n",
        "                first_learned[example_id] = np.nan\n",
        "\n",
        "    return presentations_needed_to_learn, unlearned_per_presentation, margins_per_presentation, first_learned\n",
        "\n",
        "\n",
        "# Sorts examples by number of forgetting counts during training, in ascending order\n",
        "# If an example was never learned, it is assigned the maximum number of forgetting counts\n",
        "# If multiple training runs used, sort examples by the sum of their forgetting counts over all runs\n",
        "#\n",
        "# unlearned_per_presentation_all: list of dictionaries, one per training run\n",
        "# first_learned_all: list of dictionaries, one per training run\n",
        "# npresentations: number of training epochs\n",
        "#\n",
        "# Returns 2 numpy arrays containing the sorted example ids and corresponding forgetting counts\n",
        "#\n",
        "def sort_examples_by_forgetting(unlearned_per_presentation_all,\n",
        "                                first_learned_all, npresentations):\n",
        "\n",
        "    # Initialize lists\n",
        "    example_original_order = []\n",
        "    example_stats = []\n",
        "\n",
        "    for example_id in unlearned_per_presentation_all[0].keys():\n",
        "\n",
        "        # Add current example to lists\n",
        "        example_original_order.append(example_id)\n",
        "        example_stats.append(0)\n",
        "\n",
        "        # Iterate over all training runs to calculate the total forgetting count for current example\n",
        "        for i in range(len(unlearned_per_presentation_all)):\n",
        "\n",
        "            # Get all presentations when current example was forgotten during current training run\n",
        "            stats = unlearned_per_presentation_all[i][example_id]\n",
        "\n",
        "            # If example was never learned during current training run, add max forgetting counts\n",
        "            if np.isnan(first_learned_all[i][example_id]):\n",
        "                example_stats[-1] += npresentations\n",
        "            else:\n",
        "                example_stats[-1] += len(stats)\n",
        "\n",
        "    print('Number of unforgettable examples: {}'.format(\n",
        "        len(np.where(np.array(example_stats) == 0)[0])))\n",
        "    return np.array(example_original_order)[np.argsort(\n",
        "        example_stats)], np.sort(example_stats)\n",
        "\n",
        "\n",
        "# Checks whether a given file name matches a list of specified arguments\n",
        "#\n",
        "# fname: string containing file name\n",
        "# args_list: list of strings containing argument names and values, i.e. [arg1, val1, arg2, val2,..]\n",
        "#\n",
        "# Returns 1 if filename matches the filter specified by the argument list, 0 otherwise\n",
        "#\n",
        "def check_filename(fname, args_list):\n",
        "\n",
        "    # # If no arguments are specified to filter by, pass filename\n",
        "    # if args_list is None:\n",
        "    #     return 1\n",
        "\n",
        "    # for arg_ind in list(args_list):#np.arange(0, len(args_list), 2):\n",
        "    #     arg = str(arg_ind)\n",
        "    #     arg_value = str(args_list[arg_ind])\n",
        "\n",
        "    #     # Check if filename matches the current arg and arg value\n",
        "    #     if arg + '_' + arg_value + '__' not in fname:\n",
        "    #         print('skipping file: ' + fname)\n",
        "    #         return 0\n",
        "\n",
        "    return 1\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy6sKOHcN46a",
        "outputId": "ca3d58e2-ab60-4d72-b3f6-9ae206038473"
      },
      "source": [
        "\n",
        "\n",
        "args = {'output_dir': 'cifar100_results',\n",
        "        'output_name': 'cifar100_sorted',\n",
        "        'input_dir':'cifar100_results',\n",
        "        'epochs': 20,\n",
        "        'input_fname_args':\n",
        "        {\n",
        "            'dataset': 'cifar100',\n",
        "            'data_augmentation': True,\n",
        "            'cutout': False,\n",
        "            'no_droput': False,\n",
        "            'sorting_file': 'none',\n",
        "            'remove_n': 0,\n",
        "            'keep_lowest_n': 0,\n",
        "            'remove_subsample':0,\n",
        "            'noise_percent_labels':0,\n",
        "            'noise_percent_pixels':0,\n",
        "            'noise_std_pixels':0\n",
        "\n",
        "        }\n",
        "\n",
        "        }\n",
        "\n",
        "# Initialize lists to collect forgetting stastics per example across multiple training runs\n",
        "unlearned_per_presentation_all, first_learned_all = [], []\n",
        "\n",
        "for d, _, fs in os.walk(args['input_dir']):\n",
        "    for f in fs:\n",
        "\n",
        "        # Find the files that match input_fname_args and compute forgetting statistics\n",
        "        if f.endswith('stats_dict.pkl') and check_filename(\n",
        "                f, args['input_fname_args']):\n",
        "            print('including file: ' + f)\n",
        "\n",
        "            # Load the dictionary compiled during training run\n",
        "            with open(os.path.join(d, f), 'rb') as fin:\n",
        "                loaded = pickle.load(fin)\n",
        "\n",
        "            # Compute the forgetting statistics per example for training run\n",
        "            _, unlearned_per_presentation, _, first_learned = compute_forgetting_statistics(\n",
        "                loaded, args['epochs'])\n",
        "\n",
        "            unlearned_per_presentation_all.append(\n",
        "                unlearned_per_presentation)\n",
        "            first_learned_all.append(first_learned)\n",
        "\n",
        "if len(unlearned_per_presentation_all) == 0:\n",
        "    print('No input files found in {} that match {}'.format(\n",
        "        args['input_dir'], args['input_fname_args']))\n",
        "else:\n",
        "\n",
        "    # Sort examples by forgetting counts in ascending order, over one or more training runs\n",
        "    ordered_examples, ordered_values = sort_examples_by_forgetting(\n",
        "        unlearned_per_presentation_all, first_learned_all, args['epochs'])\n",
        "\n",
        "    # Save sorted output\n",
        "    if args['output_name'].endswith('.pkl'):\n",
        "        with open(os.path.join(args['output_dir'], args['output_name']),\n",
        "                  'wb') as fout:\n",
        "            pickle.dump({\n",
        "                'indices': ordered_examples,\n",
        "                'forgetting counts': ordered_values\n",
        "            }, fout)\n",
        "    else:\n",
        "        with open(\n",
        "                os.path.join(args['output_dir'], args['output_name'] + '.pkl'),\n",
        "                'wb') as fout:\n",
        "            pickle.dump({\n",
        "                'indices': ordered_examples,\n",
        "                'forgetting counts': ordered_values\n",
        "            }, fout)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "including file: dataset_cifar100__data_augmentation_False__cutout_False__seed_2__sorting_file_none__remove_n_0__keep_lowest_n_0__remove_subsample_0__noise_percent_labels_0__noise_percent_pixels_0__noise_std_pixels_0__stats_dict.pkl\n",
            "Number of unforgettable examples: 22585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrFexMJrP3A9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}